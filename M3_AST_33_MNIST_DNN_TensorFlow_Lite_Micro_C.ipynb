{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naru289/Assignment-33/blob/main/M3_AST_33_MNIST_DNN_TensorFlow_Lite_Micro_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNgLag1Euy3H"
      },
      "source": [
        "# Advanced Programme in Deep Learning (Foundations and Applications)\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment : IoT and Edge Devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tdtrlAhvIHY"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to\n",
        "\n",
        "* create TensorFlowLite model and TensorFlowLite Micro model for the MNIST data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "## Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWMVQWk58aXm"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwqosl928dBA"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GXbNUL2L6LoU"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M3_AST_33_MNIST_DNN_TensorFlow_Lite_Micro_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/mnist_train.zip\")\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/mnist_test.zip\")\n",
        "    ipython.magic(\"sx unzip mnist_train.zip\")\n",
        "    ipython.magic(\"sx unzip mnist_test.zip\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer1():\n",
        "  try:\n",
        "    if not Answer1:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer1\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 1\")\n",
        "    return None\n",
        "\n",
        "def getAnswer2():\n",
        "  try:\n",
        "    if not Answer2:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer2\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 2\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lt0mMy7FHQd"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jQqZuk7FLEY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import math\n",
        "# Set seed for experiment reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkhQAiRu70SK"
      },
      "outputs": [],
      "source": [
        "# Define paths to model files\n",
        "# Creating the MNIST_DIGIT_EXP directory to move the csv files to it\n",
        "if not os.path.exists('MNIST_DIGIT_EXP'):\n",
        "    os.mkdir('MNIST_DIGIT_EXP')\n",
        "\n",
        "MODELS_DIR = 'MNIST_DIGIT_EXP/models'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + '/tensor_flowmodel'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + '/model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + \"/quant_model.tflite\"\n",
        "MODEL_TFLITE_MICRO_QUANT = MODELS_DIR + '/quant_model.cc'\n",
        "MODEL_TFLITE_MICRO_NO_QUANT = MODELS_DIR + '/no_quant_model.cc'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysPKcd8kGLnE"
      },
      "source": [
        "### Loading MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqyyuSJ4GO4b"
      },
      "outputs": [],
      "source": [
        "train_dataset = pd.read_csv('/content/mnist_train.csv' , header=None)\n",
        "test_dataset = pd.read_csv('/content/mnist_test.csv' , header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcJnPw4WGTyg"
      },
      "outputs": [],
      "source": [
        "# Converting the pandas dataframe to numpy array\n",
        "traindatasetnp = np.array(train_dataset)\n",
        "testdatasetnp = np.array(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scyTHHYYGlcU"
      },
      "outputs": [],
      "source": [
        "# The shape attribute for numpy arrays returns the dimensions of the array\n",
        "# For example, if Y has n rows and m columns, then Y.shape is (n,m). So Y.shape[0] is n\n",
        "print(traindatasetnp.shape[0], traindatasetnp.shape[1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwMPIeHbHphj"
      },
      "outputs": [],
      "source": [
        "# Make a copy of the train and test sets with datasize and 784 pixel values\n",
        "train_data = traindatasetnp[:,1:traindatasetnp.shape[1]].copy();\n",
        "test_data = testdatasetnp[:,1:testdatasetnp.shape[1]].copy();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq_l_4-TITn7"
      },
      "outputs": [],
      "source": [
        "# Check for the shape\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T7CojHNI0fx"
      },
      "outputs": [],
      "source": [
        "# Make a copy of the train and test labels from the numpy array\n",
        "train_labels = traindatasetnp[:,0].copy();\n",
        "test_labels = testdatasetnp[:,0].copy();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEk-E3lOJDe8"
      },
      "outputs": [],
      "source": [
        "# Check for the shape of labels\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrTcfspiJL6Q"
      },
      "outputs": [],
      "source": [
        "# Converting train and test data to float32 array\n",
        "train_data_scaled = np.array(train_data, np.float32)\n",
        "test_data_scaled = np.array(test_data, np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ26LI3pKRT8"
      },
      "outputs": [],
      "source": [
        "print(train_data_scaled[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KEJ3MWTVw1o"
      },
      "outputs": [],
      "source": [
        "# Make a copy of the float converted data\n",
        "train_data = train_data_scaled.copy()\n",
        "test_data = test_data_scaled.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo8GUEEsMqQT"
      },
      "source": [
        "### Visualizing the image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk5AH1fzJI2Q"
      },
      "outputs": [],
      "source": [
        "# 255 corresponds to white data, the closer it is to 255 it will correspond to a white pixel\n",
        "# the closer it is to zero it wil correspond to black pixels\n",
        "# Reshaping 784 to 28*28\n",
        "# from train_data taking 369 row for visualization\n",
        "cv2_imshow(255*(train_data[369].reshape(28,28)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4gDolyhMxYG"
      },
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBl0Qz_DM3wp"
      },
      "outputs": [],
      "source": [
        "# Label encoding for train data\n",
        "traindata = (train_labels.size, train_labels.max()+1)\n",
        "print(traindata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jBMh6Y6Noyi"
      },
      "outputs": [],
      "source": [
        "# one hot encode the train labels\n",
        "one_hot_train_labels = np.zeros(traindata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir0Hv1a3OMgg"
      },
      "outputs": [],
      "source": [
        "rows = np.arange(train_labels.size)\n",
        "print(rows.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ht47NNQOZPW"
      },
      "outputs": [],
      "source": [
        "one_hot_train_labels[rows, train_labels] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVmKaqqzKKVD"
      },
      "outputs": [],
      "source": [
        "print(train_labels)\n",
        "print(one_hot_train_labels)\n",
        "print(one_hot_train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq7cl3luPG44"
      },
      "outputs": [],
      "source": [
        "# Label encoding for test data\n",
        "testdata = (test_labels.size, test_labels.max()+1)\n",
        "one_hot_test_labels = np.zeros(testdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47wgyfwLavoY"
      },
      "outputs": [],
      "source": [
        "rows = np.arange(test_labels.size)\n",
        "one_hot_test_labels[rows, test_labels] = 1\n",
        "print(one_hot_test_labels)\n",
        "print(one_hot_test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSVCYL-7PQYP"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM8cw5FbQ0m2"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Only takes one feature\n",
        "# Input of 784\n",
        "model.add(keras.layers.Dense(100, activation='relu', input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "# Only one output\n",
        "model.add(keras.layers.Dense(10))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[\"mae\"]) # tf.keras.losses.BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTgy7Xx-RIMu"
      },
      "source": [
        "We can also go for higher number of nodes also for better accuracy and for better convergence, but we have to finally put in the hardware so need to make sure that we compress it as much as possible in the training phase itself. So that there is not much loss when we perform quantization and pruning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKq4_3szQ1v6"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g8uXqAiMEVo"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_data, one_hot_train_labels, epochs=500, batch_size=600,\n",
        "                    validation_data=(test_data, one_hot_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMDJLgBHPx_j"
      },
      "outputs": [],
      "source": [
        "# Save the model to disk\n",
        "model.save(MODEL_TF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA-3l4tu8H8Y"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_mae = model.evaluate(test_data_scaled, one_hot_test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nMQ9hsAvIg4"
      },
      "outputs": [],
      "source": [
        "# Get the model predictions on test data\n",
        "y_test_pred = model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECR9RWTJP9e7"
      },
      "outputs": [],
      "source": [
        "# Visualize and print the actual and predicted image\n",
        "cv2_imshow(255*test_data[163].reshape(28,28))\n",
        "np.argmax(y_test_pred[163])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQBhEJy_-86h"
      },
      "outputs": [],
      "source": [
        "x_test = tf.convert_to_tensor(train_data, dtype=tf.float32)\n",
        "def representative_dataset():\n",
        "  for i in range(300):\n",
        "    yield([tf.reshape(x_test[i],(1, 784))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPNg5AzKQXJI"
      },
      "source": [
        "### Convert the model to TFLite without quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO9UGqyZQWFP"
      },
      "outputs": [],
      "source": [
        "# Convert the model to TFLite without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6dY2TSnQmIC"
      },
      "source": [
        "### Convert and save the model with quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "croTaCg78PHn"
      },
      "outputs": [],
      "source": [
        "# Convert and save the model with quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Enforce integer only quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  #TFLITE_BUILTINS\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# Create and provide a representative dataset\n",
        "converter.representative_dataset = representative_dataset\n",
        "model_tflite = converter.convert()\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0q4QoP7TfV0"
      },
      "source": [
        "The tflite model has 92432 total number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLgEtz72T0YP"
      },
      "outputs": [],
      "source": [
        "# TFLite with no quant\n",
        "x_test = test_data.copy()\n",
        "# Converting test data to float32 array\n",
        "x_test = x_test.astype(np.float32)\n",
        "\n",
        "x_labels = one_hot_test_labels.copy()\n",
        "# Converting the test labels to float32 array\n",
        "x_labels = x_labels.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hix86UF0UQxH"
      },
      "outputs": [],
      "source": [
        "# Initialize and allocate memory without quantization\n",
        "no_q_interpreter = tf.lite.Interpreter(model_content=model_no_quant_tflite)\n",
        "\n",
        "# Load the TFLite model and allocate tensors\n",
        "no_q_interpreter.allocate_tensors() # Needed before execution!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmwpUnHTUDss"
      },
      "outputs": [],
      "source": [
        "# Get input tensors.\n",
        "no_q_interpreter.get_input_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpaQcBkHU2TV"
      },
      "outputs": [],
      "source": [
        "# Get output tensors\n",
        "no_q_interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGgQRj94EMeh"
      },
      "outputs": [],
      "source": [
        "y_test_pred_no_quant_tflite = np.empty(x_labels.shape, dtype=np.float32)\n",
        "print(y_test_pred_no_quant_tflite.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hqrACxfImPb"
      },
      "outputs": [],
      "source": [
        "# Check the predictions on the tensorflow lite model on test data\n",
        "for i in range(len(x_test)):\n",
        "    input_shape = no_q_interpreter.get_input_details()[0]['shape'];\n",
        "    inputtensor = np.array(x_test[i].reshape(input_shape), dtype=np.float32)\n",
        "    no_q_interpreter.set_tensor(no_q_interpreter.get_input_details()[0][\"index\"], inputtensor)\n",
        "    # Run inference\n",
        "    no_q_interpreter.invoke()\n",
        "    y_test_pred_no_quant_tflite[i,:] = no_q_interpreter.get_tensor(no_q_interpreter.get_output_details()[0][\"index\"])[0]\n",
        "\n",
        "cv2_imshow(x_test[12].reshape(28,28))\n",
        "print(np.argmax(y_test_pred_no_quant_tflite[12]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG_6484dXO8j"
      },
      "source": [
        "### TensorFLow Lite Micro\n",
        "\n",
        "TensorFLow Lite still operates in floating point, now micro controllers, let's say embedded controllers, which supports floating point operation, can put the tensorflow lite into those microcontrollers. But there are some microcontrollers which does not support floating point hardware, they might support floating point software, for the hardware which doesn't support floating point for that we need to reduce the size which convert this floating point 32 bit data into a 8 bit integer data and then we could use these models which are approximately 1/4 size of the TensorFlow lite model and then we can put these models into microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAl9Zi9y8SA_"
      },
      "outputs": [],
      "source": [
        "x_test = test_data.copy()\n",
        "x_test = x_test.astype(np.float32)\n",
        "x_labels = one_hot_test_labels.copy()\n",
        "x_labels = x_labels.astype(np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSt3__S3V72P"
      },
      "outputs": [],
      "source": [
        "# Initialize and allocate memory with quantization\n",
        "q_interpreter = tf.lite.Interpreter(model_content=model_tflite)\n",
        "q_interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0jV4HJlWH2a"
      },
      "outputs": [],
      "source": [
        "# Get the input and output tensors\n",
        "q_interpreter.get_input_details()\n",
        "q_interpreter.get_output_details()\n",
        "\n",
        "input_details = q_interpreter.get_input_details()[0]\n",
        "output_details = q_interpreter.get_output_details()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85JXPXFEWMoa"
      },
      "outputs": [],
      "source": [
        "input_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlwDps0VWObn"
      },
      "outputs": [],
      "source": [
        "output_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xZabEm2WSAC"
      },
      "outputs": [],
      "source": [
        "input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "\n",
        "x_test_ = x_test / input_scale + input_zero_point\n",
        "\n",
        "x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
        "print(x_test_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP6VpoBh8XoX"
      },
      "outputs": [],
      "source": [
        "# Invoke the interpreter with quantization\n",
        "y_test_pred_tflite = np.empty(x_labels.shape, dtype=output_details[\"dtype\"])\n",
        "for i in range(len(x_test_)):\n",
        "    input_shape= q_interpreter.get_input_details()[0]['shape'];\n",
        "    inputtensor = np.array(x_test_[i].reshape(input_shape), dtype=np.int8)\n",
        "    q_interpreter.set_tensor(input_details[\"index\"], inputtensor)\n",
        "    q_interpreter.invoke()\n",
        "    y_test_pred_tflite[i,:] = q_interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "y_test_pred_tflite = y_test_pred_tflite.astype(np.float32)\n",
        "y_test_pred_tflite1 = (y_test_pred_tflite - output_zero_point) * output_scale\n",
        "\n",
        "cv2_imshow(x_test[12].reshape(28,28))\n",
        "print(np.argmax(y_test_pred_tflite[12]))\n",
        "\n",
        "print(x_test_[12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcVVZbku81YP"
      },
      "outputs": [],
      "source": [
        "#!apt-get update && apt-get -qq install xxd\n",
        "!apt-get -qq install xxd\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO_QUANT}\n",
        "# Print the C source file\n",
        "!cat {MODEL_TFLITE_MICRO_QUANT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZPh1U5DLATi"
      },
      "outputs": [],
      "source": [
        "#!apt-get update && apt-get -qq install xxd\n",
        "!apt-get -qq install xxd\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "!xxd -i {MODEL_NO_QUANT_TFLITE} > {MODEL_TFLITE_MICRO_NO_QUANT}\n",
        "# Print the C source file\n",
        "!cat {MODEL_TFLITE_MICRO_NO_QUANT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcWp7rRr1E7Y"
      },
      "outputs": [],
      "source": [
        "# Another Way of getting the array in .h file\n",
        "def hex_to_c_array(hex_data, var_name):\n",
        "\n",
        "  c_str = ''\n",
        "\n",
        "  # Create header guard\n",
        "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
        "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
        "\n",
        "  # Add array length at top of file\n",
        "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
        "\n",
        "  # Declare C variable\n",
        "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
        "  hex_array = []\n",
        "  for i, val in enumerate(hex_data) :\n",
        "\n",
        "    # Construct string from hex\n",
        "    hex_str = format(val, '#04x')\n",
        "\n",
        "    # Add formatting so each line stays within 80 characters\n",
        "    if (i + 1) < len(hex_data):\n",
        "      hex_str += ','\n",
        "    if (i + 1) % 12 == 0:\n",
        "      hex_str += '\\n '\n",
        "    hex_array.append(hex_str)\n",
        "\n",
        "  # Add closing brace\n",
        "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
        "\n",
        "  # Close out header guard\n",
        "  c_str += '#endif //' + var_name.upper() + '_H'\n",
        "\n",
        "  return c_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FlW_9roLhLT"
      },
      "outputs": [],
      "source": [
        "c_model_name = \"model_tflite_no_quant\"\n",
        "with open(c_model_name + '.h', 'w') as file:\n",
        "  file.write(hex_to_c_array(model_no_quant_tflite , c_model_name)) # model_tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vDJHlw3Lj2f"
      },
      "outputs": [],
      "source": [
        "c_model_name = \"model_tflite_quant\"\n",
        "with open(c_model_name + '.h', 'w') as file:\n",
        "  file.write(hex_to_c_array(model_tflite, c_model_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4dyTLUPvif"
      },
      "source": [
        ". h files are header files that are prewritten for our compiler. .cc files are our C source code files in which our code is written and are created by the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVeaZ50Qb4nq"
      },
      "outputs": [],
      "source": [
        "input = np.array([test_data[145,:]]);\n",
        "print((input.dtype))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZoQ6H1pN--b"
      },
      "outputs": [],
      "source": [
        "y_test_pred_single = model.predict(input)\n",
        "cv2_imshow(255*input.reshape(28,28))\n",
        "np.argmax(y_test_pred_single)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7fitFsxdfU4"
      },
      "source": [
        "TensorFlow Lite is a set of tools that enables on-device machine learning by helping developers run their models on mobile, embedded, and IoT devices. One of the key features is, it is optimized for on-device machine learning, by addressing 5 key constraints:\n",
        "\n",
        "\n",
        "A. **Latency** : There's no round-trip to a server  \n",
        "\n",
        "B. **Privacy** : No personal data leaves the device\n",
        "\n",
        "C. **Connectivity** : Internet connectivity is not required\n",
        "\n",
        "D. **Size** : Reduced model and binary size\n",
        "\n",
        "E. **Power consumption** : Efficient inference and a lack of network connections\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NHDYadgG-RHl"
      },
      "outputs": [],
      "source": [
        "#@title Q.1. Which of the above statement(s) about TensorFlow Lite is/are True?\n",
        "Answer1 = \"\" #@param [\"\",\"Only A and B\",\"Only B and D\",\"Only C and D\", \"Only D and E\", \"All of the above\",\"None of the above\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fNBEvP4lHm-"
      },
      "source": [
        "#### Consider the following statements given below and answer Q2.\n",
        "\n",
        "A. It is possible to convert a TensorFlow model into a TensorFlow Lite model by using TensorFlow Lite Converter.\n",
        "\n",
        "B. During conversion (TensorFlow model into a TensorFlow Lite model), we can apply optimizations such as quantization to reduce model size and latency with minimal or no loss in accuracy.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Qu3sufDD7pu1"
      },
      "outputs": [],
      "source": [
        "#@title Q.2. Which of the above statement(s) is/are True?\n",
        "Answer2 = \"\" #@param [\"\",\"Only A\", \"Only B\", \"Both A and B\", \"Neither A nor B\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}